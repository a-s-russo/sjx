# WARNING - Generated by {fusen} from dev/flat_save_data.Rmd: do not edit by hand

#' @title
#' Download and clean ABS time series data
#' 
#' @description
#' `download_ts` downloads the time series data corresponding to a table of an
#' ABS publication, imports them into R, cleans and reformats the data, and
#' then returns a list containing tibbles of the series data and series
#' metadata.
#'
#' @details
#' The URL needs to be a link to the downloadable Excel file corresponding to a
#' table on the webpage of an ABS publication, and not a link to the webpage
#' itself. To obtain such a link (in Windows and using Microsoft Edge), navigate
#' to the 'Data downloads' tab of a publication, right-click on the 'Download
#' XLSX' hyperlink for the chosen table, and select 'Copy link'.
#' 
#' Only the most recent 500 observations for the series are read in, as
#' X-13ARIMA-SEATS will fail to execute if the series are too long.
#' 
#' The included series start and end variables in the metadata ('Index' sheet of
#' the downloaded spreadsheet) are ignored. The reason is because some series
#' values in the data ('Data1' sheet) are suppressed or missing at the start
#' and/or end of the series, meaning these included variables don't align with
#' what's really in the data sheet containing the time series values. By
#' creating series start and end variables based on the common span across all
#' series in the data sheet, errors are reduced for series with potentially
#' missing data at the start and/or end periods. Furthermore, for a given table
#' (spreadsheet), all plots have the same time scale, which aids comparisons.
#' 
#' Some original series may also have suppressed or missing values in the middle
#' of them (rather than at the start and/or end). These series are removed from
#' the returned datasets since seasonally adjusted and trend estimates cannot be
#' generated from them by X-13ARIMA-SEATS or JDemetra+ due to the missingness.
#' (ABS seasonally adjusted and trend series with suppressed or missing values
#' in the middle are retained since these only need to be compared or 
#' displayed.)
#' 
#' Any seasonally adjusted and trend series that do not have a corresponding
#' original series in the ABS data are also removed. This is because seasonally
#' adjusted and trend estimates cannot be generated without an original series,
#' obviously, so there is nothing to compare or display. (Therefore, if an
#' original series is removed because of missingness in the middle as
#' described above, then its corresponding seasonally adjusted and trend
#' series will also be removed.)
#'
#' @param url download link to the data
#' 
#' @importFrom dplyr all_of any_of filter mutate rename select select_if slice_tail
#' @importFrom httr http_error
#' @importFrom janitor clean_names
#' @importFrom lubridate month quarter year ymd
#' @importFrom readxl excel_sheets read_excel
#' @importFrom rlang .data
#' @importFrom stats na.omit
#' @importFrom utils download.file
#' @importFrom zoo na.trim
#' 
#' @return series data and metadata
#' 
#' @examples
#' \dontrun{
#' # Construct a URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/economy/" # ABS website (for economic statistics)
#' pub <- "business-indicators/business-indicators-australia/" # Publication
#' ref <- "mar-2023/" # Reference period
#' cat <- "567600" # Catalogue number
#' tab <- "3" # Table number
#' ext <- ".xlsx" # File extension
#' URL <- paste0(ABS, pub, ref, cat, tab, ext)
#'
#' # Download the series data and metadata
#' sales <- download_ts(URL)
#' }
#'
#' @export
download_ts <- function(url) {
  # Check for valid URL
  stopifnot("The URL is not a string" = is.character(url) == TRUE)
  stopifnot("The URL could not be found" = !http_error(url) == TRUE)
  stopifnot("The URL does not link to the ABS website" = startsWith(url, "https://www.abs.gov.au/"))
  stopifnot("The URL does not link to a data download file on the ABS website" = endsWith(url, ".xlsx"))
  
  messages <- character(0)
  
  # Download data spreadsheet
  raw_data <- tempfile(fileext = ".xlsx")
  download.file(url,
                raw_data,
                method = "auto",
                mode = "wb",
                quiet = TRUE)
  stopifnot(
    "The 'Index' and/or 'Data1' sheets were not found in the downloaded ABS spreadsheet file" = all(c("Index", "Data1") %in% excel_sheets(raw_data))
  )
  
  # Read series data sheet
  series_data <- read_excel(raw_data, sheet = "Data1", skip = 9) |>
    rename(period = "Series ID") |>
    mutate(period = as.Date(.data$period))
  
  # The order of the following operations is important!
  
  # Remove series for which all observations are suppressed or missing
  empty_series <- colnames(select_if(series_data, ~all(is.na(.))))
  series_data <- select(series_data, -(all_of(empty_series)))
  stopifnot(
    "After removing series for which all observations are suppressed or missing, no series exist in the series data sheet" = ncol(series_data) > 1
  )
  if (length(empty_series) != 0)
    messages <-
    c(
      messages,
      "Series for which all observations are suppressed or missing have been removed"
    )
  
  # Remove trailing and leading observations that are suppressed or missing
  nrow_before_trimming <- nrow(series_data)
  series_data <- na.trim(series_data)
  nrow_after_trimming <- nrow(series_data)
  if (nrow_before_trimming != nrow_after_trimming)
    messages <-
    c(
      messages,
      "Periods at the start and/or end of any series with suppressed or missing data have been removed from all series"
    )
  
  # Read in series metadata
  series_metadata <-
    read_excel(
      raw_data,
      sheet = "Index",
      skip = 9,
      col_names = TRUE,
      .name_repair = "unique_quiet"
    )
  
  # Remove original series with suppressed or missing observations in the middle
  orig_series <- series_metadata |>
    filter(series_metadata$`Series Type` == "Original") |>
    pull("Series ID") # Extract series IDs for original series
  partial_series <-
    colnames(select_if(series_data, ~any(is.na(.)))) # Identify any series with suppressed or missing observations
  partial_series <-
    intersect(partial_series, orig_series) # Limit to only original series
  series_data <- select(series_data, -(all_of(partial_series)))
  stopifnot(
    "After removing original series with suppressed or missing observations in the middle of them, no series exist in the series data sheet" = ncol(series_data) > 1
  )
  if (length(partial_series) != 0)
    messages <-
    c(
      messages,
      "Original series with suppressed or missing observations in the middle of them have been removed"
    )
  
  # Restrict to most recent observations
  nrow_before_slicing <- nrow(series_data)
  series_data <-
    slice_tail(series_data, n = 500) # X-13 in 'seas' will fail if series is too long, so select most recent data
  nrow_after_slicing <- nrow(series_data)
  if (nrow_before_slicing != nrow_after_slicing)
    messages <-
    c(
      messages,
      "The lengths of the series are potentially too long for X-13ARIMA-SEATS; only the most recent 500 observations for each have been included"
    )
  
  # Check for the existence of only original series in the initially downloaded spreadsheet file before any data cleaning
  orig_msg_flag <-
    FALSE # Existence of only original series also checked later after data cleaning, so don't warn twice
  if (length(setdiff(na.omit(series_metadata$`Series Type`), "Original")) == 0) {
    messages <-
      c(messages,
        "The downloaded ABS spreadsheet file only contains original series")
    orig_msg_flag <- TRUE
  }
  
  # Remove irrelevant metadata
  series_metadata <- series_metadata |>
    select_if(~!all(is.na(.))) |> # Discard empty columns
    na.omit() |> # Discard junk (empty and copyright) rows; note this must come after discarding any empty columns!
    clean_names() |>
    within(rm(list = c("series_start", "series_end"))) |>
    filter(!(.data$series_id %in% c(empty_series, partial_series))) # Remove empty and partial series
  freq <- unique(series_metadata$freq)
  stopifnot(
    "The downloaded ABS spreadsheet file contains series of frequencies other than monthly or quarterly" = (freq %in% c("Month", "Quarter"))
  )
  if ((freq == "Month" &
       nrow(series_data) < 12 * 3) |
      (freq == "Quarter" & nrow(series_data) < 4 * 3)) {
    stop(
      "The lengths of the series are too short; at least three year's worth of data are required"
    )
  }
  
  # Create common start and end dates across series
  series_metadata <- series_metadata |>
    mutate(
      common_series_start = as.Date(series_data$period[1]),
      common_series_end = as.Date(series_data$period[nrow(series_data)]),
      common_start_year = as.Date(year(ymd(
        .data$common_series_start
      ))),
      common_start_period = as.Date(ifelse(
        series_metadata$freq == "Month", month(ymd(.data$common_series_start)), quarter(ymd(.data$common_series_start))
      )),
      common_end_year = as.Date(year(ymd(
        .data$common_series_end
      ))),
      common_end_period = as.Date(ifelse(
        series_metadata$freq == "Month", month(ymd(.data$common_series_end)), quarter(ymd(.data$common_series_end))
      ))
    )
  
  # Create numeric version of frequency variable
  series_metadata <- series_metadata |>
    mutate(
      freq_name = .data$freq,
      freq_num = ifelse(series_metadata$freq == "Quarter", 4, 12)
    ) |>
    within(rm("freq"))
  
  # Create variables for the publication and table titles
  titles <-
    read_excel(
      raw_data,
      sheet = "Index",
      range = "B5:B6",
      col_names = FALSE,
      .name_repair = "unique_quiet"
    )
  title_pub <- as.character(titles[1, 1])
  title_tab <- as.character(titles[2, 1])
  series_metadata <- series_metadata |>
    mutate(publication = title_pub,
           table = title_tab)
  
  # Keep only seasonally adjusted and trend series that have a corresponding original series
  nrow_before_excluding <- nrow(series_metadata)
  dataItems_tokeep <-
    series_metadata$data_item_description[series_metadata$series_type == "Original"]
  series_metadata <- series_metadata |>
    filter(.data$data_item_description %in% dataItems_tokeep)
  stopifnot(
    "After removing seasonally adjusted and/or trend series without a corresponding original series, no series remain" = nrow(series_metadata) > 0
  )
  nrow_after_excluding <- nrow(series_metadata)
  if (nrow_before_excluding != nrow_after_excluding)
    messages <-
    c(
      messages,
      "Seasonally adjusted and/or trend series without a corresponding original series have been removed"
    )
  seriesIDs_tokeep <- series_metadata$series_id
  series_data <- series_data |>
    select(any_of(c("period", seriesIDs_tokeep)))
  if (length(setdiff(series_metadata$series_type, "Original")) == 0 &
      orig_msg_flag == FALSE)
    messages <-
    c(messages, "After data cleaning, only original series exist")
  
  # Check for matching series IDs in the series data and metadata
  data_seriesIDs <- colnames(select(series_data, -"period"))
  meta_seriesIDs <- series_metadata$series_id
  stopifnot(
    "After data cleaning, the series IDs do not match across the series data and metadata sheets" = length(setdiff(data_seriesIDs, meta_seriesIDs)) == 0
  )
  
  # Generate list of series data and metadata
  results <- list(data = series_data, meta = series_metadata)
  
  # Return messages
  for (message in messages)
    message(message)
  
  return(results)
}

#' @title
#' Generate seasonally adjusted and trend estimates via X-13ARIMA-SEATS
#' 
#' @description
#' `run_X13` executes the United States Census Bureau's X-13ARIMA-SEATS program
#' to generate the seasonally adjusted and trend estimates for a time series
#' object (containing original estimates), and returns these in a list.
#' 
#' @details
#' Seasonal adjustment and trending are performed using the `seasonal` interface
#' to X-13ARIMA-SEATS. Execution is done using X-13 rather than SEATS; otherwise
#' all default values are used in the execution call.
#' 
#' @param ts time series object
#' 
#' @importFrom seasonal seas
#' 
#' @return seasonally adjusted and trend estimates generated by X-13ARIMA-SEATS
#' 
#' @export
run_X13 <- function(ts) {
  output <- seas(ts, x11 = "") # X11 option specifies X-11; overrides the 'seats' spec
  results <- list("seas" = output$data[, "seasonaladj"],
                  "tren" = output$data[, "trend"])
  return(results)
}

#' @title
#' Generate seasonally adjusted and trend estimates via JDemetra+
#' 
#' @description
#' `run_RJD` executes the Eurostat's JDemetra+ program to generate the
#' seasonally adjusted and trend estimates for a time series object (containing
#' original estimates), and returns these in a list.
#' 
#' @details
#' Seasonal adjustment and trending are performed using the `RJDemetra`
#' interface to JDemetra+ (version 2). Execution is done using X-13 rather than
#' SEATS; otherwise all default values are used in the execution call.
#' 
#' @param ts time series object
#' 
#' @importFrom RJDemetra x13
#' 
#' @return seasonally adjusted and trend estimates generated by JDemetra+
#' 
#' @export
run_RJD <- function(ts) {
  output <- x13(ts)
  results <- list("seas" = output$final$series[, "sa"],
                  "tren" = output$final$series[, "t"])
  return(results)
}

#' @title
#' Create a time series object for a single series
#' 
#' @description
#' `create_ts` returns a time series object for a single series in a downloaded
#' and cleaned table from an ABS publication (as returned by `download_ts`).
#' The series is identified by its series ID contained in the series metadata.
#' 
#' @details
#' To maintain consistency with other structures and functions used in this
#' package, a NULL object (rather than an error) is returned if the series ID is
#' missing.
#' 
#' @param series list returned from `download_ts` containing series data and
#' metadata
#' @param seriesID series ID
#' 
#' @importFrom dplyr filter pull
#' @importFrom rlang .data
#' @importFrom stats ts
#' 
#' @return time series object for a single series
#' 
#' @examples
#' \dontrun{
#' # Construct URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/labour/" # ABS website (for labour statistics)
#' pub <- "employment-and-unemployment/labour-force-australia/" # Publication
#' ref <- "jul-2023/" # Reference period
#' cat <- "620200" # Catalogue number
#' tab <- "1" # Table number
#' ext <- ".xlsx" # File extension
#' URL <- paste0(ABS, pub, ref, cat, tab, ext)
#'
#' # Run function
#' emp_total <- create_ts(emp, "A84423127L")
#' }
#'
#' @export
create_ts <- function(series, seriesID) {
  # Return NULL object if series ID is missing
  if (length(seriesID) == 0)
    return(NULL)
  
  # Extract series data and metadata
  data <- series$data
  meta <- series$meta
  
  # Create common start and end periods
  common_start_year <-
    filter(meta, .data$series_id == seriesID)$common_start_year
  common_start_month <-
    filter(meta, .data$series_id == seriesID)$common_start_period
  common_end_year <-
    filter(meta, .data$series_id == seriesID)$common_end_year
  common_end_month <-
    filter(meta, .data$series_id == seriesID)$common_end_period
  
  # Redefine frequency variable
  freq <- filter(meta, .data$series_id == seriesID)$freq_num
  
  # Generate time series object
  results <- ts(
    pull(data, seriesID),
    start = c(common_start_year, common_start_month),
    end = c(common_end_year, common_end_month),
    frequency = freq
  )
  
  return(results)
}

#' @title
#' Generate original, seasonally adjusted and trend estimates for a single data
#' item description
#' 
#' @description
#' `create_ts_comp` returns a list containing the following for a single data
#' item description:
#' * the series metadata
#' * the original ABS series
#' * the seasonally adjusted and trend ABS series (where available)
#' * the seasonally adjusted and trend series generated by X-13ARIMA-SEATS and
#' JDemetra+
#' 
#' @details
#' Requires the data output from `download_ts`. If the ABS seasonally adjusted
#' and/or trend estimates are not published, then they will not exist in the
#' list (rather than assume NULL values, for instance).
#' 
#' @param series list returned from `download_ts` containing series data and
#' metadata
#' @param dataItem data item description for which results are to be returned
#' 
#' @return series metadata, and original, seasonally adjusted and trend series,
#' for a single data item description
#' 
#' @examples
#' \dontrun{
#' # Construct URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/labour/" # ABS website (for labour statistics)
#' pub <- "employment-and-unemployment/labour-force-australia/" # Publication
#' ref <- "jul-2023/" # Reference period
#' cat <- "620200" # Catalogue number
#' tab <- "1" # Table number
#' ext <- ".xlsx" # File extension
#' URL <- paste0(ABS, pub, ref, cat, tab, ext)
#'
#' # Run function
#' emp_total <- create_ts_comp(emp, "Employed total ;  Persons ;")
#' }
#'
#' @export
create_ts_comp <- function(series, dataItem) {
  # Extract series metadata
  meta <-
    filter(series$meta, .data$data_item_description == dataItem)
  
  # Extract series IDs
  seriesID_orig <- meta$series_id[meta$series_type == "Original"]
  seriesID_seas <- meta$series_id[meta$series_type == "Seasonally Adjusted"]
  seriesID_tren <- meta$series_id[meta$series_type == "Trend"]
  
  # Generate ABS original, seasonally adjusted and trend time series object
  ABS_orig_ts <- create_ts(series, seriesID_orig)
  ABS_seas_ts <- create_ts(series, seriesID_seas)
  ABS_tren_ts <- create_ts(series, seriesID_tren)
  
  # Generate X-13ARIMA-SEATS seasonally adjusted and trend time series objects
  X13_output <- run_X13(ABS_orig_ts)
  X13_seas_ts <- X13_output$seas
  X13_tren_ts <- X13_output$tren
  
  # Generate JDemetra+ seasonally adjusted and trend time series objects
  RJD_output <- run_RJD(ABS_orig_ts)
  RJD_seas_ts <- RJD_output$seas
  RJD_tren_ts <- RJD_output$tren
  
  # Return list of time series objects
  results <- list("metadata" = meta, "ABS_orig" = ABS_orig_ts)
  if (!is.null(ABS_seas_ts))
    # Series might not be published in ABS data
    results <-
    append(results, list("ABS_seas" = ABS_seas_ts))
  if (!is.null(ABS_tren_ts))
    # Series might not be published in ABS data
    results <-
    append(results, list("ABS_tren" = ABS_tren_ts))
  results <- append(
    results,
    list(
      "X13_seas" = X13_seas_ts,
      "X13_tren" = X13_tren_ts,
      "RJD_seas" = RJD_seas_ts,
      "RJD_tren" = RJD_tren_ts
    )
  )
  
  return(results)
}

#' @title
#' Generate original, seasonally adjusted and trend estimates for all data
#' item descriptions
#' 
#' @description
#' `create_ts_table` returns a list of lists, each sub-list of which corresponds
#' to a single data item description, and contains the following for each one:
#' * the series metadata
#' * the original ABS series
#' * the seasonally adjusted and trend ABS series (where available)
#' * the seasonally adjusted and trend series generated by X-13ARIMA-SEATS and
#' JDemetra+
#' 
#' @details
#' Requires the data output from `download_ts`. NULL values appear in place of
#' non-existent series in the list returned.
#' 
#' @param series list returned from `download_ts` containing series data and
#' metadata
#' 
#' @return series metadata, and original, seasonally adjusted and trend series,
#' for all data item descriptions
#' 
#' @examples
#' \dontrun{
#' # Construct URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/labour/" # ABS website (for labour statistics)
#' pub <- "employment-and-unemployment/labour-force-australia/" # Publication
#' ref <- "jul-2023/" # Reference period
#' cat <- "620200" # Catalogue number
#' tab <- "1" # Table number
#' ext <- ".xlsx" # File extension
#' URL <- paste0(ABS, pub, ref, cat, tab, ext)
#'
#' # Run function
#' emp_all <- create_ts_table(emp)
#' }
#'
#' @export
create_ts_table <- function(series) {
  # Extract series metadata
  meta <- series$meta
  
  # Extract unique data item descriptions
  unique_dataItems <- unique(meta$data_item_description)
  no_unique_dataItems <- length(unique_dataItems)
  
  # Initialise empty list
  results <- vector("list", no_unique_dataItems)
  names(results) <- unique_dataItems
  
  # Provide progress update
  message(paste("Processing", no_unique_dataItems, "series..."))
  
  # Cycle through each data item description
  for (dataItem in unique_dataItems) {
    # Provide progress update
    message(paste0(
      "Series ",
      which(dataItem == unique_dataItems),
      "/",
      no_unique_dataItems,
      ": \"",
      dataItem,
      "\""
    ))
    
    # Extract and generate time series objects for current data item description
    results[[dataItem]] <- create_ts_comp(series, dataItem)
  }
  
  return(results)
}

#' @title
#' Generate a long data frame of original, seasonally adjusted and trend
#' estimates for a single data item description
#' 
#' @description
#' `create_tsdf_comp` returns a list containing the following for a single data
#' item description:
#' * the series metadata
#' * a long data frame containing the original, seasonally adjusted and trend
#' estimates from the ABS, X-13ARIMA-SEATS, and JDemetra+ (where available)
#' 
#' @details
#' Requires the data output from `download_ts`. If the ABS seasonally adjusted
#' and/or trend estimates are not published, then they will not exist in the
#' long data frame (rather than assume NULL values, for instance).
#' 
#' This function is useful for converting the data into a format ready to be
#' plotted. (For example, plotting with ggplot2 requires data frames, not time
#' series objects.)
#'
#' @param series list returned from `download_ts` containing series data and
#' metadata
#' @param dataItem data item description for which results are to be returned
#' 
#' @importFrom lubridate ceiling_date days
#' @importFrom reshape2 melt
#' @importFrom stats time
#' @importFrom zoo as.Date
#' 
#' @return series metadata, and long data frame of original, seasonally adjusted
#' and trend series, for a single data item description
#' 
#' @examples
#' \dontrun{
#' # Construct URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/labour/" # ABS website (for labour statistics)
#' pub <- "employment-and-unemployment/labour-force-australia/" # Publication
#' ref <- "jul-2023/" # Reference period
#' cat <- "620200" # Catalogue number
#' tab <- "1" # Table number
#' ext <- ".xlsx" # File extension
#' URL <- paste0(ABS, pub, ref, cat, tab, ext)
#'
#' # Run function
#' emp_total <- create_tsdf_comp(emp, "Employed total ;  Persons ;")
#' }
#'
#' @export
create_tsdf_comp <- function(series, dataItem) {
  # Extract time series objects for given data item description
  dataItem_ts <- create_ts_comp(series, dataItem)
  
  # Convert into data frame
  freq_type <- tolower(unique(dataItem_ts$metadata$freq_name))
  results <-
    data.frame("period" = ceiling_date(as.Date(dataItem_ts$ABS_orig), unit = freq_type) - days(1)) # Set date to last day of period (to ensure that quarterly data refers to the last month in the quarter rather than the first or second)
  if (!is.null(dataItem_ts$ABS_seas))
    # Series might not be published in ABS data
    results <-
    cbind(results, "ABS_seas" = as.numeric(dataItem_ts$ABS_seas))
  results <-
    cbind(
      results,
      "X13_seas" = as.numeric(dataItem_ts$X13_seas),
      "RJD_seas" = as.numeric(dataItem_ts$RJD_seas)
    )
  if (!is.null(dataItem_ts$ABS_tren))
    # Series might not be published in ABS data
    results <-
    cbind(results, "ABS_tren" = as.numeric(dataItem_ts$ABS_tren))
  results <-
    cbind(
      results,
      "X13_tren" = as.numeric(dataItem_ts$X13_tren),
      "RJD_tren" = as.numeric(dataItem_ts$RJD_tren)
    )
  
  # Convert into long data frame
  results <- melt(
    results,
    id.vars = c("period"),
    measusure.vars = c(
      "ABS_seas",
      "X13_seas",
      "RJD_seas",
      "ABS_tren",
      "X13_tren",
      "RJD_tren"
    ),
    value.name = "value",
    variable.name = "method"
  )
  
  # Return list of series metadata and data frame
  results <-
    list("metadata" = dataItem_ts$metadata, "dataframe" = results)
  
  return(results)
}

#' @title
#' Generate a long data frame of original, seasonally adjusted and trend
#' estimates for all data item descriptions
#' 
#' @description
#' `create_tsdf_table` returns a list of lists, each sub-list of which
#' corresponds to a single data item description, and contains the following for
#' each one:
#' * the series metadata
#' * a long data frame containing the original, seasonally adjusted and trend
#' estimates from the ABS, X-13ARIMA-SEATS, and JDemetra+ (where available)
#' 
#' @details
#' Requires the data output from `download_ts`. NULL values appear in place of
#' non-existent series in the list returned.
#' 
#' @param series list returned from `download_ts` containing series data and
#' metadata
#' 
#' @return series metadata, and long data frame of original, seasonally adjusted
#' and trend series, for all data item descriptions
#' 
#' @examples
#' \dontrun{
#' # Construct URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/labour/" # ABS website (for labour statistics)
#' pub <- "employment-and-unemployment/labour-force-australia/" # Publication
#' ref <- "jul-2023/" # Reference period
#' cat <- "620200" # Catalogue number
#' tab <- "1" # Table number
#' ext <- ".xlsx" # File extension
#' URL <- paste0(ABS, pub, ref, cat, tab, ext)
#'
#' # Run function
#' emp_all <- create_tsdf_table(emp)
#' }
#'
#' @export
create_tsdf_table <- function(series) {
  # Extract series metadata
  meta <- series$meta
  
  # Extract unique data item descriptions
  unique_dataItems <- unique(meta$data_item_description)
  no_unique_dataItems <- length(unique_dataItems)
  
  # Initialise empty list
  results <- vector("list", no_unique_dataItems)
  names(results) <- unique_dataItems
  
  # Provide progress update
  message(paste("Processing", no_unique_dataItems, "series..."))
  
  # Cycle through each data item description
  for (dataItem in unique_dataItems) {
    # Provide progress update
    message(paste0(
      "Series ",
      which(dataItem == unique_dataItems),
      "/",
      no_unique_dataItems,
      ": \"",
      dataItem,
      "\""
    ))
    
    # Extract and generate time series objects for current data item description
    results[[dataItem]] <- create_tsdf_comp(series, dataItem)
  }
  
  return(results)
}

#' @title
#' Generate ggplots for seasonally adjusted and trend estimates for a single
#' data item description
#' 
#' @description
#' `create_tsplot_table` returns a list of ggplot objects for the seasonally
#' adjusted and trend series corresponding to a single data item description in
#' a downloaded and cleaned table from an ABS publication (as returned by
#' `download_ts`).
#' 
#' @details
#' Requires the data output from `download_ts`. If the ABS seasonally adjusted
#' or trend estimates are not published, then a ggplot is still returned
#' containing only the seasonally adjusted or trend estimates generated by
#' X-13ARIMA-SEATS and JDemetra+.
#'
#' @param series list returned from `download_ts` containing series data and
#' metadata
#' @param dataItem data item description for which results are to be returned
#' 
#' @importFrom ggplot2 aes element_text geom_line ggplot labs margin
#' scale_color_discrete scale_y_continuous theme xlab ylab
#' @importFrom ggtext element_textbox_simple
#' @importFrom lubridate year
#' @importFrom rlang .data
#' @importFrom stringr str_squish
#' 
#' @return ggplot objects for the seasonally adjusted and trend series for a
#' single data item description
#' 
#' @examples
#' \dontrun{
#' # Construct URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/labour/" # ABS website (for labour statistics)
#' pub <- "employment-and-unemployment/labour-force-australia/" # Publication
#' ref <- "jul-2023/" # Reference period
#' cat <- "620200" # Catalogue number
#' tab <- "1" # Table number
#' ext <- ".xlsx" # File extension
#' URL <- paste0(ABS, pub, ref, cat, tab, ext)
#'
#' # Run function
#' create_tsplot_comp(emp, "Employed total ;  Persons ;")
#'
#' # Plot still produced even when ABS seasonally adjusted and/or trend non-existent:
#' create_tsplot_comp(emp, "Civilian population aged 15 years and over ;  Persons ;")
#' }
#'
#' @export
create_tsplot_comp <- function(series, dataItem) {
  # Extract time series data frame for given data item description
  dataItem_df <- create_tsdf_comp(series, dataItem)
  
  # Extract relevant information for plotting purposes
  series_description <- dataItem
  units <- as.character(unique(dataItem_df$metadata[, "unit"]))
  
  # Initialise empty list
  results <- list("seas" = NULL, "tren" = NULL)
  
  # Cycle through each series type
  for (type in c("seas", "tren")) {
    # Extract series to be plotted
    if (type == "seas")
      plot_data <-
        dataItem_df$dataframe[dataItem_df$dataframe$method %in% c("ABS_seas", "X13_seas", "RJD_seas"),]
    if (type == "tren")
      plot_data <-
        dataItem_df$dataframe[dataItem_df$dataframe$method %in% c("ABS_tren", "X13_tren", "RJD_tren"),]
    
    # Extract start and end periods for plotting purposes
    start_date <- unique(plot_data$period)[1]
    start_yr <- as.character(year(start_date))
    end_date <-
      unique(plot_data$period)[length(unique(plot_data$period))]
    end_yr <- as.character(year(end_date))
    freq <- tolower(unique(dataItem_df$metadata$freq_name))
    start_period <- format(unique(plot_data$period)[1], "%B")
    end_period <-
      format(unique(plot_data$period)[length(unique(plot_data$period))], "%B")
    period_qualifter <- ifelse(freq == "quarter", "Qtr", "")
    timespan <-
      str_squish(
        paste(
          start_period,
          period_qualifter,
          start_yr,
          "to",
          end_period,
          period_qualifter,
          end_yr
        )
      )
    
    # Extract legend labels for plotting purposes
    if (type == "seas") {
      if ("Seasonally Adjusted" %in% dataItem_df$metadata$series_type)
        labels <- c("ABS", "X13", "RJD")
      else
        labels <-
          c("X13", "RJD") # Series might not be published in ABS data
    }
    if (type == "tren") {
      if ("Trend" %in% dataItem_df$metadata$series_type)
        labels <- c("ABS", "X13", "RJD")
      else
        labels <-
          c("X13", "RJD") # Series might not be published in ABS data
    }
    
    # Generate plot object
    plot <- ggplot(
      plot_data,
      aes(
        x = .data$period,
        y = .data$value,
        group = .data$method,
        colour = .data$method
      )
    ) +
      geom_line() +
      labs(title = series_description,
           subtitle = paste0(
             ifelse(type == "seas", "Seasonally Adjusted", "Trend"),
             " (",
             units,
             ")"
           )) +
      theme(
        plot.title = element_textbox_simple(halign = 0.5, margin = margin(10, 0, 10, 0)),
        plot.subtitle = element_text(hjust = 0.5)
      ) + # 'element_textbox_simple' automatically wraps long titles
      xlab(paste0("\n", timespan)) +
      ylab("") +
      scale_color_discrete(name = "Method", labels = labels) +
      scale_y_continuous(labels = scales::comma)
    
    # Append plot for current series type
    results[[type]] <- plot
  }
  
  return(results)
}

#' @title
#' Generate ggplots for seasonally adjusted and trend estimates for all data
#' item descriptions
#' 
#' @description
#' `create_tsplot_table` returns a list of ggplot objects for the seasonally
#' adjusted and trend series corresponding to all data item descriptions in a
#' downloaded and cleaned table from an ABS publication (as returned by
#' `download_ts`).
#' 
#' @details
#' Requires the data output from `download_ts`. If the ABS seasonally adjusted
#' and/or trend estimates are not published, then a ggplot is still returned
#' containing only the seasonally adjusted or trend estimates generated by
#' X-13ARIMA-SEATS and JDemetra+.
#'
#' @param series list returned from `download_ts` containing series data and
#' metadata
#' 
#' @return ggplot objects for the seasonally adjusted or trend series for all
#' data item descriptions
#' 
#' @examples
#' \dontrun{
#' # Construct URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/labour/" # ABS website (for labour statistics)
#' pub <- "employment-and-unemployment/labour-force-australia/" # Publication
#' ref <- "jul-2023/" # Reference period
#' cat <- "620200" # Catalogue number
#' tab <- "1" # Table number
#' ext <- ".xlsx" # File extension
#' URL <- paste0(ABS, pub, ref, cat, tab, ext)
#'
#' # Run function
#' emp_plots <- create_tsplot_table(emp)
#' }
#'
#' @export
create_tsplot_table <- function(series) {
  # Extract series metadata
  meta <- series$meta
  
  # Extract unique data item descriptions
  unique_dataItems <- unique(meta$data_item_description)
  no_unique_dataItems <- length(unique_dataItems)
  
  # Initialise empty list
  results <- vector("list", no_unique_dataItems)
  names(results) <- unique_dataItems
  
  # Provide progress update
  message(paste("Processing", no_unique_dataItems, "series..."))
  
  # Cycle through each data item description
  for (dataItem in unique_dataItems) {
    # Provide progress update
    message(paste0(
      "Series ",
      which(dataItem == unique_dataItems),
      "/",
      no_unique_dataItems,
      ": \"",
      dataItem,
      "\""
    ))
    
    # Generate and append seasonally adjusted and trend plots for current data item description
    results[[dataItem]] <- create_tsplot_comp(series, dataItem)
  }
  
  return(results)
}
