---
title: "Comparison of seasonal adjustment and trending methods on Australian data"
subtitle: "Save data"
author: "Anthony Russo"
date: "`r Sys.Date()`"
output: html_document
---

## Seasonal adjustment and trending

A time series is a collection of well-defined data observed regularly through
time. Seasonal adjustment is an analytical method to estimate and remove
seasonal and calendar-related impacts from a time series. Trending is an
analytical method to estimate the long-term, underlying direction of a time
series.

This analysis compares the seasonal adjustment and trending methods produced by
the following three programs:

* [SEASABS](https://www.abs.gov.au/websitedbs/d3310114.nsf/4a256353001af3ed4b2562bb00121564/c890aa8e65957397ca256ce10018c9d8!OpenDocument) (used by Australia's national statistical agency)

* [X-13ARIMA-SEATS](https://www.census.gov/data/software/x13as.html) (used by
the United States Census Bureau)

* [JDemetra+](https://jdemetradocumentation.github.io/JDemetra-documentation/)
(used by many European statistical agencies and central banks)

Published seasonally adjusted and trend estimates of time series data from the
Australian Bureau of Statistics (generated via SEASABS) are compared against the
output generated by executing the X-13ARIMA-SEATS and JDemetra+ programs. Since
SEASABS is not freely available, the estimates are referenced directly via their
publications on the web. The other two programs are readily accessible however,
and in this analysis, they are run via R interfaces:

* The R package `seas` is used to run X-13ARIMA-SEATS

* The R package `RJDemetra` is used to run JDemetra+

Importantly, the default values of both packages have been used when running the
seasonal adjustment and trending algorithms.

## ABS time series data

The [Australian Bureau of Statistics](https://www.abs.gov.au/) (ABS) produces
seasonally adjusted and trend estimates for various publications containing
original time series. The relevant data are contained in various tables as Excel
spreadsheets under the 'Data downloads' section of the desired publication.

An example is *Table 1. Inventories, chain volume measures* in the March
2023 publication of 'Business Indicators, Australia' available at:

[https://www.abs.gov.au/statistics/economy/business-indicators/business-indicators-australia/mar-2023/5676001.xlsx](https://www.abs.gov.au/statistics/economy/business-indicators/business-indicators-australia/mar-2023/5676001.xlsx)

Each spreadsheet file contains the following sheets/tabs:

* **Index:** contains metadata about the time
series, such as the series type, units and frequency

* **Data1:** contains the original, seasonally adjusted and trend
estimates (any other tabs are ignored in this analysis)

## Loading required packages

```{r libraries, warning=FALSE, message=FALSE}
library(dplyr)
library(janitor)
library(lubridate)
library(readxl)
```

## Downloading and cleaning the data

The function below downloads and cleans the data and metadata via a given URL.
The URL points to the download link for a particular table of a particular
publication.

Note that the included series start and  end variables in the metadata ('Index'
tab of the downloaded spreadsheet) are ignored. The reason is because some
series values in the data ('Data1' tab) are suppressed, meaning these included
variables don't align with what's really in the data tab containing the time
series values. By creating series start and end variables based on the common
span across all series in the data tab ('complete cases'), errors are reduced
for series with potentially missing data at the start or end periods, and for a
given table (spreadsheet), all plots have the same time scale which aids
comparisons.

```{r function-download_ts}
#' download_ts Download and clean ABS time series data
#'
#' @param url Download link to the data
#' @details The URL needs to be a link to the downloadable Excel file corresponding to a table on the webpage of an ABS publication, and not a link to the webpage itself. To obtain such a link (in Windows and using Microsoft Edge), navigate to the 'Data downloads' tab of a publication, right-click on the 'Download XLSX' hyperlink for the chosen table, and select 'Copy link'.
#' @importFrom dplyr filter mutate rename select_if slice_tail
#' @importFrom janitor clean_names
#' @importFrom lubridate month quarter year ymd
#' @importFrom readxl read_excel
#' @importFrom stats na.omit
#' @importFrom utils download.file
#' @return A list containing tibbles of series and their metadata
#' @export
download_ts <- function(url) {
  # Download data
  raw_data <- tempfile(fileext = ".xlsx")
  download.file(url, raw_data, method = "auto", mode = "wb")
  series_data <- read_excel(raw_data, sheet = "Data1", skip = 9) |>
    slice_tail(n = 500) |> # X-13 in 'seas' will fail if series is too long, so select most recent data
    rename(period = "Series ID") |>
    na.omit() # Some series have different start and end dates, so reduce dataset to complete cases across series
  
  # Download metadata
  series_metadata <-
    read_excel(raw_data,
               sheet = "Index",
               skip = 9,
               col_names = TRUE)
  
  # Remove irrelevant data
  series_metadata <- series_metadata |>
    filter(grepl("^[A-Z][a-z]+", "Data Item Description")) |> # Discard junk (empty and copyright) rows
    select_if( ~ !all(is.na(.))) |> # Discard empty columns
    clean_names()
  
  # Create common start and end dates across series
  series_metadata <- series_metadata |>
    mutate(
      common_series_start = series_data$period[1],
      common_series_end = series_data$period[nrow(series_data)],
      common_start_year = year(ymd("common_series_start")),
      common_start_period = ifelse("freq" == "Month", month(ymd(
        "common_series_start"
      )), quarter(ymd(
        "common_series_start"
      ))),
      common_end_year = year(ymd("common_series_end")),
      common_end_period = ifelse("freq" == "Month", month(ymd(
        "common_series_end"
      )), quarter(ymd(
        "common_series_end"
      )))
    )
  
  # Create numeric version of frequency variable
  series_metadata <- series_metadata |>
    mutate(freq_name = "freq",
           freq_num = ifelse("freq" == "Quarter", 4, 12)) |>
    within(rm("freq"))
  
  # Create variables for the publication and table titles
  titles <-
    read_excel(raw_data,
               sheet = "Index",
               range = "B5:B6",
               col_names = FALSE)
  title_pub <- as.character(titles[1, 1])
  title_tab <- as.character(titles[2, 1])
  series_metadata <- series_metadata |>
    mutate(publication = title_pub,
           table = title_tab)
  
  return(list(data = series_data, meta = series_metadata))
}
```

## Creating the time series

The following functions create the time series data ready to be seasonally
adjusted or trended, or plotted.

```{r function-create_ts_groups}
#' create_ts_groups Create matching groups of series IDs
#'
#' @param series A list returned from download_ts containing series and their metadata
#' @details This function creates matching groups of series IDs from the metadata ('Index' tab of the downloaded ABS spreadsheet) corresponding to original, seasonally adjusted and trend series (in the 'Data1' tab of the spreadsheet). This is necessary to ensure matching series are plotted together by data item description. Note though that seasonally adjusted and trend series are not necessarily available for all original time series.
#' @importFrom dplyr filter pull
#' @return A list containing character vectors of matching groups of original, seasonally adjusted and trend series IDs
#' @export
create_ts_groups <- function(series) {
  # Extract series metadata
  meta <- series$meta
  
  # Extract series groups
  unique_series_names <- pull(unique(meta["data_item_description"]))
  
  # Initialise vectors to store matching series IDs by index number
  series_ID_orig <- character()
  series_ID_seas <- character()
  series_ID_tren <- character()
  
  # Cycle through each group of series
  for (name_index in 1:length(unique_series_names)) {
    # Filter data to extract current series group
    unique_name <- unique_series_names[name_index]
    data_filtered <-
      filter(meta, "data_item_description" == unique_name)
    
    # Cycle through each series in group
    for (row in 1:nrow(data_filtered)) {
      # Extract series type and populate vectors
      if (data_filtered[row, "series_type"] == "Original")
        series_ID_orig <-
          c(series_ID_orig, as.character(data_filtered[row, "series_id"]))
      if (data_filtered[row, "series_type"] == "Seasonally Adjusted")
        series_ID_seas <-
          c(series_ID_seas, as.character(data_filtered[row, "series_id"]))
      if (data_filtered[row, "series_type"] == "Trend")
        series_ID_tren <-
          c(series_ID_tren, as.character(data_filtered[row, "series_id"]))
    }
    
    # Insert blanks where series are absent in spreadsheet to ensure corresponding vectors of series IDs are aligned
    if (length(series_ID_orig) < name_index)
      series_ID_orig <- c(series_ID_orig, "")
    if (length(series_ID_seas) < name_index)
      series_ID_seas <- c(series_ID_seas, "")
    if (length(series_ID_tren) < name_index)
      series_ID_tren <- c(series_ID_tren, "")
  }
  
  return(list(
    orig = series_ID_orig,
    seas = series_ID_seas,
    tren = series_ID_tren
  ))
}
```

```{r function-create_ts}
#' create_ts Create time series objects from downloaded and cleaned ABS time series data
#'
#' @param series A list returned from download_ts containing series and their metadata
#' @param name A series ID
#' @details This function creates the time series objects ready for extraction, seasonal adjustment or trending, or plotting.
#' @importFrom dplyr filter
#' @importFrom stats ts
#' @return A time series object
#' @export
create_ts <- function(series, name) {
  # Extract series data and metadata
  data <- series$data
  meta <- series$meta
  
  # Create common start and end periods
  common_start_year <-
    filter(meta, "series_id" == name)$common_start_year
  common_start_month <-
    filter(meta, "series_id" == name)$common_start_period
  common_end_year <- filter(meta, "series_id" == name)$common_end_year
  common_end_month <-
    filter(meta, "series_id" == name)$common_end_period
  
  # Redefine frequency variable
  freq <- filter(meta, "series_id" == name)$freq_num
  
  return(ts(
    data[, name],
    start = c(common_start_year, common_start_month),
    end = c(common_end_year, common_end_month),
    frequency = freq
  ))
}
```

## Plotting the time series

The following function plots the seasonally adjusted or trend series produced by
X-13ARIMA-SEATS or JDemetra+ against the ABS version.

```{r function-plot_ts}
#' create_ts Create time series objects from downloaded and cleaned ABS time series data
#'
#' @param series A list returned from download_ts containing series and their metadata
#' @param type Optional: "S" for seasonally adjusted plots, or "T" for trend plots. Defaults to "S"
#' @details Requires the data output from download_ts, and calls the time series generation functions (create_groups and create_ts) during execution. Where an original series is not accompanied by seasonally adjusted or trend series, it will not be plotted as there is nothing to compare.
#' @importFrom dplyr filter
#' @importFrom ggplot2 aes element_text geom_line ggplot labs margin scale_x_date scale_y_continuous theme xlab ylab
#' @importFrom ggtext element_textbox_simple
#' @importFrom reshape2 melt
#' @importFrom RJDemetra x13
#' @importFrom seasonal seas
#' @return A list of ggplot objects
#' @export
plot_ts <- function(series,
                    type = "S") {
  # Extract series data and metadata
  data <- series$data
  meta <- series$meta
  
  # Initialise list to store plots
  plot_list <- list() # Length not known in advance since some iterations below are possibly skipped over
  
  # Extract groups and series IDs
  series_groups <- create_ts_groups(series)
  series_ID_orig <- series_groups$orig
  if (type == "S")
    series_ID_othr <- series_groups$seas
  if (type == "T")
    series_ID_othr <- series_groups$tren
  
  # Cycle through series
  for (series_index in 1:length(series_ID_orig)) {
    # Skip iteration when only the original series are present for a given group but not the SA or T series
    if (series_ID_othr[series_index] == "")
      next
    
    # Extract relevant series metadata for generating required series and for plotting purposes
    X13_type <- ifelse(type == "S", "seasonaladj", "trend")
    RJD_type <- ifelse(type == "S", "sa", "t")
    plot_type <- ifelse(type == "S", "Seasonally Adjusted", "Trend")
    series_description <-
      filter(meta, "series_id" == series_ID_othr[series_index])$data_item_description
    units <-
      filter(meta, "series_id" == series_ID_orig[series_index])$unit
    period_type <-
      ifelse(meta$freq_name[1] == "Quarter", "quarters", "months")
    period_range <-
      seq(data$period[1], data$period[nrow(data)], period_type)
    
    # Extract ABS original and seasonally adjusted/trend series
    ABS_orig <- create_ts(series, series_ID_orig[series_index])
    ABS <- create_ts(series, series_ID_othr[series_index])
    
    # Generate X-13ARIMA-SEATS seasonally adjusted/trend series
    X13 <-
      seas(ABS_orig, x11 = "")$data[, X13_type] # X11 option specifies X-11; overrides the 'seats' spec
    
    # Generate JDemetra+ seasonally adjusted/trend series
    RJD <- x13(ABS_orig, spec = "RSA5c")$final$series[, RJD_type]
    
    # Generate plot data
    plot_data <-
      data.frame(
        "ABS" = as.numeric(ABS),
        "X13" = as.numeric(X13),
        "RJD" = as.numeric(RJD),
        "Period" = as.Date(period_range)
      ) |>
      melt(
        id.vars = c("Period"),
        value.name = "Value",
        variable.name = "Method"
      )
    
    # Generate plot
    p <-
      ggplot(plot_data,
             aes(
               x = "Period",
               y = "Value",
               group = "Method",
               colour = "Method"
             )) +
      geom_line() +
      labs(title = series_description,
           subtitle = paste0(plot_type, " (", units, ")")) +
      theme(
        plot.title = element_textbox_simple(halign = 0.5, margin = margin(10, 0, 10, 0)),
        plot.subtitle = element_text(hjust = 0.5)
      ) + # 'element_textbox_simple' automatically wraps long titles
      xlab("") +
      ylab("") +
      scale_x_date(
        date_breaks = "5 years",
        date_labels = "%Y",
        date_minor_breaks = "1 year"
      ) +
      scale_y_continuous(labels = scales::comma_format())
    
    # Append plot to list of plots
    plot_list[[length(plot_list) + 1]] <- p
  }
  
  return(plot_list)
}
```

```{r, examples-make_plot, echo=FALSE, eval=FALSE}
#' \dontrun{
#' # Construct URL to download ABS data
#' ABS <- "https://www.abs.gov.au/statistics/economy/" # ABS website (for economic statistics)
#' pub <- "business-indicators/business-indicators-australia/" # Publication
#' ref <- "mar-2023/" # Reference period
#' cat <- "567600" # Catalogue number
#' tab <- "3.xlsx" # Table number
#' URL <- paste0(ABS, pub, ref, cat, tab)
#' 
#' # Download and plot data
#' sales <- download_ts(URL)
#' sales_plots <- plot_ts(sales, "T")
#' for (p in sales_plots) print(p)
#' }
```